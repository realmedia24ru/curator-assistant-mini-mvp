import os, re, csv, io, time, httpx
from typing import List, Dict, Any, Optional

SYSTEM_PROMPT = (
    "–¢—ã ‚Äî –∫—É—Ä–∞—Ç–æ—Ä –æ–Ω–ª–∞–π–Ω-–ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –∏—Å–∫—É—Å—Å—Ç–≤—É. "
    "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –±–µ–∑ –æ–±—â–∏—Ö —Å–ª–æ–≤."
)
COURSE_HINTS = (
    "–°—Å—ã–ª–∫–∏: <–ø—Ä–∞–≤–∏–ª–∞>, <–∞–Ω–∫–µ—Ç–∞>, <–≤–≤–æ–¥–Ω–∞—è>, <–±–∞–∑–∞_–∑–∞—â–∏—Ç>. "
    "–ù–µ –∑–∞–±—ã–≤–∞–π –ø—Ä–æ #–æ—Å–µ–±–µ –∏ #–¢–æ—á–∫–∞–ê, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ –±–∞–∑—É –∑–∞—â–∏—Ç."
)

LINKS = {
    "<–ø—Ä–∞–≤–∏–ª–∞>": "https://t.me/c/2471800961/20",
    "<–∞–Ω–∫–µ—Ç–∞>": "https://forms.gle/mUYXTjswVtxWVpvJA",
    "<–≤–≤–æ–¥–Ω–∞—è>": "https://t.me/c/2471800961/1737",
    "<–±–∞–∑–∞_–∑–∞—â–∏—Ç>": "https://onstudy.org/courses/baza-zaschit-hudozhnikov-2-0/",
}

def expand_links(txt: str) -> str:
    if not txt:
        return txt
    out = txt
    pats = [
        (r"<\s*–ø—Ä–∞–≤–∏–ª[–∞-—è]*\s*>", LINKS["<–ø—Ä–∞–≤–∏–ª–∞>"]),
        (r"<\s*–∞–Ω–∫–µ—Ç[–∞-—è]*\s*>",  LINKS["<–∞–Ω–∫–µ—Ç–∞>"]),
        (r"<\s*–≤–≤–æ–¥–Ω[–∞-—è]*\s*>",  LINKS["<–≤–≤–æ–¥–Ω–∞—è>"]),
        (r"<\s*–±–∞–∑[–∞—ã]\s*[_\-\s]*–∑–∞—â–∏—Ç[–∞-—è]*\s*>", LINKS["<–±–∞–∑–∞_–∑–∞—â–∏—Ç>"]),
    ]
    for pat, url in pats:
        out = re.sub(pat, url, out, flags=re.I)
    for k, v in LINKS.items():
        out = out.replace(k, v)
    return out

KB_CSV_URL  = os.getenv("KB_CSV_URL", "")
KB_CSV_PATH = os.getenv("KB_CSV_PATH", "kb/kb_rules.csv")

_ACK = [
    "—Å–ø–∞—Å–∏–±–æ","—Å–ø–∞—Å–∏–±","–æ–∫","–æ–∫–µ–π","–ø–æ–Ω—è–ª","–ø–æ–Ω—è–ª–∞","–∞–≥–∞","—É–≥—É",
    "–∫–ª–∞—Å—Å","—Å—É–ø–µ—Ä","–æ—Ç–ª–∏—á–Ω–æ","ok","thx","thanks"
]
def _is_ack(text: str) -> bool:
    t = (text or "").lower()
    return ("?" not in t) and any(w in t for w in _ACK) and len(t) <= 120

def _parse_patterns(cell: str):
    if not cell:
        return []
    parts = re.split(r"[;|]", cell)
    out=[]
    for p in parts:
        p = p.strip()
        if not p:
            continue
        if p == "*":
            out.append(("star", "*"))
            continue
        if p.lower().startswith("re:"):
            try:
                rgx = re.compile(p[3:], re.I | re.S)
                out.append(("re", rgx))
            except re.error:
                pass
        else:
            out.append(("str", p.lower()))
    return out

_rows: List[Dict[str, Any]] = []
_loaded_at: float = 0.0

def _load_rows_from_text(text: str) -> List[Dict[str, Any]]:
    if text.startswith("\ufeff"):  # BOM
        text = text.lstrip("\ufeff")
    reader = csv.DictReader(io.StringIO(text))
    rows = []
    for rec in reader:
        pat = _parse_patterns((rec.get("patterns") or "").strip())
        s1  = (rec.get("s1") or "").strip()
        s2  = (rec.get("s2") or "").strip()
        pr  = (rec.get("priority") or "0").strip()
        try:
            pr = int(pr)
        except:
            pr = 0
        if not pat or (not s1 and not s2):
            continue
        rows.append({"patterns": pat, "s1": s1, "s2": s2, "priority": pr})
    rows.sort(key=lambda r: r["priority"], reverse=True)
    return rows

async def reload_kb():
    """–ì–æ—Ä—è—á–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–∑ Google Sheets CSV –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    global _rows, _loaded_at
    text = ""
    src  = ""
    if KB_CSV_URL:
        src = KB_CSV_URL
        async with httpx.AsyncClient(timeout=30) as c:
            r = await c.get(KB_CSV_URL, follow_redirects=True)
            r.raise_for_status()
            text = r.text
    else:
        src = KB_CSV_PATH
        with open(KB_CSV_PATH, "r", encoding="utf-8") as f:
            text = f.read()

    _rows = _load_rows_from_text(text)
    _loaded_at = time.time()
    return {"ok": True, "rows": len(_rows), "src": src, "loaded_at": _loaded_at}

def _score(text: str, row: Dict[str, Any]) -> Optional[int]:
    t = (text or "")
    tl = t.lower()
    hit = False
    sc  = 0
    for kind, patt in row["patterns"]:
        if kind == "star":
            hit = True
            sc  = max(sc, 1)
        elif kind == "str":
            if patt in tl:
                hit = True
                sc = max(sc, 10)
        elif kind == "re":
            if patt.search(t):
                hit = True
                sc = max(sc, 20)
    return (sc + row["priority"]) if hit else None

def _fallback_pair() -> List[str]:
    return [
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ, –∫ –∫–∞–∫–æ–º—É –º–æ–¥—É–ª—é –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –≤–æ–ø—Ä–æ—Å ‚Äî –ø–æ–º–æ–≥—É –±—ã—Å—Ç—Ä–æ —Å–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è.",
        "‚úÖ –ú–∏–Ω–∏-–ø–ª–∞–Ω: 1) <–≤–≤–æ–¥–Ω–∞—è>, 2) <–∞–Ω–∫–µ—Ç–∞>, 3) #–¢–æ—á–∫–∞–ê."
    ]

def rule_suggestions(user_text: str) -> List[str]:
    if _is_ack(user_text):
        return [
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –ï—Å–ª–∏ –ø–æ—è–≤—è—Ç—Å—è –≤–æ–ø—Ä–æ—Å—ã ‚Äî –ø–∏—à–∏—Ç–µ —Å—é–¥–∞, –ø–æ–º–æ–∂–µ–º.",
            "–†–∞–¥–∞ –ø–æ–º–æ—á—å üíú –í–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –ª–µ–∫—Ü–∏—è–º –∏ —á–∞—Ç—É, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —É–¥–æ–±–Ω–æ."
        ]
    if not _rows:
        return _fallback_pair()

    best = None
    best_sc = -10**9
    for r in _rows:
        sc = _score(user_text, r)
        if sc is not None and sc > best_sc:
            best, best_sc = r, sc

    if best:
        s1 = best.get("s1") or "‚Ä¶"
        s2 = best.get("s2") or "‚Ä¶"
        return [s1, s2]

    return _fallback_pair()

# ---------- –≠–∫—Å–ø–æ—Ä—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG-–≤–∞—Ä–∏–∞–Ω—Ç–∞ ----------
def get_kb_snippets() -> List[Dict[str, str]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ kb_rules –¥–ª—è RAG-–æ—Ç–≤–µ—Ç–∞."""
    out: List[Dict[str, str]] = []
    for i, r in enumerate(_rows):
        s1 = r.get("s1") or ""
        s2 = r.get("s2") or ""
        if s1:
            out.append({"id": f"kb:{i}:s1", "text": expand_links(s1)})
        if s2:
            out.append({"id": f"kb:{i}:s2", "text": expand_links(s2)})
    return out
